{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "NUM_CLASSES = 10\n",
    "input_shape = (28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMALIZTION\n",
    "x_train_normalized = x_train.astype('float32') / 255.0\n",
    "x_test_normalized = x_test.astype('float32') / 255.0\n",
    "y_train_cat = keras.utils.to_categorical(y_train)\n",
    "y_test_cat = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 64)        32832     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 64)          102464    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 142186 (555.41 KB)\n",
      "Trainable params: 142186 (555.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (4, 4), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (5, 5), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath='models/DIGITZ_best.h5',\n",
    "                            #  save_format='keras', \n",
    "                             monitor='val_accuracy',  \n",
    "                             verbose=2, \n",
    "                             save_best_only=True)\n",
    "\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9909\n",
      "Epoch 1: val_accuracy improved from -inf to 0.98625, saving model to models/DIGITZ_best.h5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0286 - accuracy: 0.9910 - val_loss: 0.0464 - val_accuracy: 0.9862\n",
      "Epoch 2/30\n",
      "  20/1500 [..............................] - ETA: 8s - loss: 0.0234 - accuracy: 0.9937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ginger/miniforge3/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9933\n",
      "Epoch 2: val_accuracy did not improve from 0.98625\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0514 - val_accuracy: 0.9862\n",
      "Epoch 3/30\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9946\n",
      "Epoch 3: val_accuracy improved from 0.98625 to 0.98867, saving model to models/DIGITZ_best.h5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.0405 - val_accuracy: 0.9887\n",
      "Epoch 4/30\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9950\n",
      "Epoch 4: val_accuracy did not improve from 0.98867\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.0518 - val_accuracy: 0.9874\n",
      "Epoch 5/30\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9961\n",
      "Epoch 5: val_accuracy did not improve from 0.98867\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0641 - val_accuracy: 0.9844\n",
      "Epoch 6/30\n",
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9964\n",
      "Epoch 6: val_accuracy did not improve from 0.98867\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.0525 - val_accuracy: 0.9880\n",
      "Epoch 7/30\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9968\n",
      "Epoch 7: val_accuracy improved from 0.98867 to 0.98900, saving model to models/DIGITZ_best.h5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0510 - val_accuracy: 0.9890\n",
      "Epoch 8/30\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9971\n",
      "Epoch 8: val_accuracy did not improve from 0.98900\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.0433 - val_accuracy: 0.9887\n",
      "Epoch 9/30\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 9: val_accuracy improved from 0.98900 to 0.98908, saving model to models/DIGITZ_best.h5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0524 - val_accuracy: 0.9891\n",
      "Epoch 10/30\n",
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9973\n",
      "Epoch 10: val_accuracy improved from 0.98908 to 0.98925, saving model to models/DIGITZ_best.h5\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0495 - val_accuracy: 0.9893\n",
      "Epoch 11/30\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9973\n",
      "Epoch 11: val_accuracy improved from 0.98925 to 0.98967, saving model to models/DIGITZ_best.h5\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0453 - val_accuracy: 0.9897\n",
      "Epoch 12/30\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9975\n",
      "Epoch 12: val_accuracy did not improve from 0.98967\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0655 - val_accuracy: 0.9871\n",
      "Epoch 13/30\n",
      "1494/1500 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9984\n",
      "Epoch 13: val_accuracy did not improve from 0.98967\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0626 - val_accuracy: 0.9893\n",
      "Epoch 14/30\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9982\n",
      "Epoch 14: val_accuracy improved from 0.98967 to 0.98983, saving model to models/DIGITZ_best.h5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0513 - val_accuracy: 0.9898\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9985\n",
      "Epoch 15: val_accuracy did not improve from 0.98983\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0578 - val_accuracy: 0.9898\n",
      "Epoch 16/30\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9983\n",
      "Epoch 16: val_accuracy improved from 0.98983 to 0.99017, saving model to models/DIGITZ_best.h5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0497 - val_accuracy: 0.9902\n",
      "Epoch 17/30\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9980\n",
      "Epoch 17: val_accuracy did not improve from 0.99017\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0750 - val_accuracy: 0.9868\n",
      "Epoch 18/30\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 18: val_accuracy did not improve from 0.99017\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0604 - val_accuracy: 0.9896\n",
      "Epoch 19/30\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9982\n",
      "Epoch 19: val_accuracy did not improve from 0.99017\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0540 - val_accuracy: 0.9898\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 20: val_accuracy improved from 0.99017 to 0.99158, saving model to models/DIGITZ_best.h5\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0523 - val_accuracy: 0.9916\n",
      "Epoch 21/30\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 21: val_accuracy did not improve from 0.99158\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0609 - val_accuracy: 0.9907\n",
      "Epoch 22/30\n",
      "1499/1500 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9988\n",
      "Epoch 22: val_accuracy did not improve from 0.99158\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0604 - val_accuracy: 0.9884\n",
      "Epoch 23/30\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 23: val_accuracy did not improve from 0.99158\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0754 - val_accuracy: 0.9888\n",
      "Epoch 24/30\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9983\n",
      "Epoch 24: val_accuracy did not improve from 0.99158\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0543 - val_accuracy: 0.9898\n",
      "Epoch 25/30\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 25: val_accuracy did not improve from 0.99158\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0563 - val_accuracy: 0.9908\n",
      "Epoch 26/30\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9991\n",
      "Epoch 26: val_accuracy did not improve from 0.99158\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0609 - val_accuracy: 0.9908\n",
      "Epoch 27/30\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9989\n",
      "Epoch 27: val_accuracy did not improve from 0.99158\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0716 - val_accuracy: 0.9893\n",
      "Epoch 28/30\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 28: val_accuracy did not improve from 0.99158\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0680 - val_accuracy: 0.9916\n",
      "Epoch 29/30\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 29: val_accuracy did not improve from 0.99158\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0898 - val_accuracy: 0.9883\n",
      "Epoch 30/30\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9988\n",
      "Epoch 30: val_accuracy did not improve from 0.99158\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0614 - val_accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_normalized, \n",
    "                    y_train_cat, \n",
    "                    epochs=30, \n",
    "                    validation_split=0.2,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0352 - accuracy: 0.9921 - 519ms/epoch - 2ms/step\n",
      "\n",
      "Test accuracy: 0.9921000003814697\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       980\n",
      "           1       1.00      1.00      1.00      1135\n",
      "           2       1.00      0.99      0.99      1032\n",
      "           3       0.99      1.00      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       1.00      0.99      0.99       958\n",
      "           7       0.99      0.99      0.99      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       0.99      0.99      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "[[ 976    0    0    1    1    0    1    0    1    0]\n",
      " [   0 1130    0    2    0    0    2    1    0    0]\n",
      " [   1    0 1023    0    1    0    0    4    3    0]\n",
      " [   0    0    1 1005    0    3    0    0    0    1]\n",
      " [   0    0    0    0  975    0    0    2    1    4]\n",
      " [   1    0    0    6    0  879    1    1    2    2]\n",
      " [   1    1    0    0    4    4  945    0    3    0]\n",
      " [   0    3    2    1    0    0    0 1020    0    2]\n",
      " [   0    0    1    0    0    1    0    1  968    3]\n",
      " [   0    0    0    1    4    2    0    2    0 1000]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test_normalized, y_test_cat, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc}')\n",
    "\n",
    "# Print classification report\n",
    "y_pred = model.predict(x_test_normalized)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test_cat, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(model_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdigit_recogonizer.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(model_path+'digit_recogonizer.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15fae9b10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAa9klEQVR4nO3df3DU953f8deaH2vgVnunYmlXQVZUB2oPoqQBwo/DIGhQ0Y0ZY5wctm8ykCYe/xDcUOH6gukUXSaHfOTMkIts0nhyGCYQmNxgTAtnrBxI2INxZQ7HlLhEPkRQDskqstkVMl6Q+PQPytYLWOSz3uWtlZ6PmZ1Bu9833w9ff+2nv+zqq4BzzgkAAAO3WS8AADB4ESEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGBmqPUCrnX58mWdOXNGoVBIgUDAejkAAE/OOXV1damoqEi33db3tU6/i9CZM2dUXFxsvQwAwOfU2tqqMWPG9LlNv4tQKBSSJM3Un2iohhmvBgDgq0eX9Ib2Jv973pesReiFF17QD37wA7W1tWn8+PHasGGD7r333pvOXf0ruKEapqEBIgQAOef/3ZH093lLJSsfTNixY4dWrFih1atX6+jRo7r33ntVWVmp06dPZ2N3AIAclZUIrV+/Xt/+9rf1ne98R/fcc482bNig4uJibdy4MRu7AwDkqIxH6OLFizpy5IgqKipSnq+oqNChQ4eu2z6RSCgej6c8AACDQ8YjdPbsWfX29qqwsDDl+cLCQrW3t1+3fW1trcLhcPLBJ+MAYPDI2jerXvuGlHPuhm9SrVq1SrFYLPlobW3N1pIAAP1Mxj8dN3r0aA0ZMuS6q56Ojo7rro4kKRgMKhgMZnoZAIAckPEroeHDh2vSpEmqr69Peb6+vl4zZszI9O4AADksK98nVF1drW9+85uaPHmypk+frp/85Cc6ffq0Hn/88WzsDgCQo7ISocWLF6uzs1Pf+9731NbWprKyMu3du1clJSXZ2B0AIEcFnHPOehGfFo/HFQ6HVa77uWMCAOSgHndJDXpFsVhMeXl5fW7Lj3IAAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzAy1XgDQnwSG+v8rMeSO0VlYSWaceOqLac31jrzsPVNyV4f3zMgnA94z7euHe8/80+Qd3jOSdLa323tm6i9Wes98qfqw98xAwZUQAMAMEQIAmMl4hGpqahQIBFIekUgk07sBAAwAWXlPaPz48frlL3+Z/HrIkCHZ2A0AIMdlJUJDhw7l6gcAcFNZeU+oublZRUVFKi0t1UMPPaSTJ09+5raJRELxeDzlAQAYHDIeoalTp2rLli3at2+fXnzxRbW3t2vGjBnq7Oy84fa1tbUKh8PJR3FxcaaXBADopzIeocrKSj344IOaMGGCvva1r2nPnj2SpM2bN99w+1WrVikWiyUfra2tmV4SAKCfyvo3q44aNUoTJkxQc3PzDV8PBoMKBoPZXgYAoB/K+vcJJRIJvffee4pGo9neFQAgx2Q8Qk899ZQaGxvV0tKit956S1//+tcVj8e1ZMmSTO8KAJDjMv7Xcb/73e/08MMP6+zZs7rjjjs0bdo0HT58WCUlJZneFQAgx2U8Qtu3b8/0b4l+asg9Y71nXHCY98yZ2X/oPXNhmv+NJyUpP+w/9/rE9G6OOdD8w8ch75m/rpvvPfPWhG3eMy2XLnjPSNKzH8zznil63aW1r8GKe8cBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGay/kPt0P/1ln8lrbn1Lz3vPTNu2PC09oVb65Lr9Z75rz9a6j0ztNv/Zp/Tf7HMeyb0Lz3eM5IUPOt/49ORb7+V1r4GK66EAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIa7aEPBE2fSmjvySbH3zLhhH6S1r4FmZds075mT50d7z7x01997z0hS7LL/3a0L//ZQWvvqz/yPAnxxJQQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOEGplBPW3tacz/66294z/zV/G7vmSHv/oH3zK+e/JH3TLq+f/bfes+8/7WR3jO959q8Zx6Z/qT3jCSd+nP/mVL9Kq19YXDjSggAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMMMNTJG2/E1ves/c8d//lfdMb+eH3jPjy/6j94wkHZ/1d94zu38y23um4Nwh75l0BN5M76aipf7/aIG0cCUEADBDhAAAZrwjdPDgQS1YsEBFRUUKBALatWtXyuvOOdXU1KioqEgjRoxQeXm5jh8/nqn1AgAGEO8IdXd3a+LEiaqrq7vh6+vWrdP69etVV1enpqYmRSIRzZs3T11dXZ97sQCAgcX7gwmVlZWqrKy84WvOOW3YsEGrV6/WokWLJEmbN29WYWGhtm3bpscee+zzrRYAMKBk9D2hlpYWtbe3q6KiIvlcMBjU7NmzdejQjT8NlEgkFI/HUx4AgMEhoxFqb2+XJBUWFqY8X1hYmHztWrW1tQqHw8lHcXFxJpcEAOjHsvLpuEAgkPK1c+66565atWqVYrFY8tHa2pqNJQEA+qGMfrNqJBKRdOWKKBqNJp/v6Oi47uroqmAwqGAwmMllAAByREavhEpLSxWJRFRfX5987uLFi2psbNSMGTMyuSsAwADgfSV0/vx5vf/++8mvW1pa9M477yg/P1933nmnVqxYobVr12rs2LEaO3as1q5dq5EjR+qRRx7J6MIBALnPO0Jvv/225syZk/y6urpakrRkyRK99NJLevrpp3XhwgU9+eST+uijjzR16lS99tprCoVCmVs1AGBACDjnnPUiPi0ejyscDqtc92toYJj1cpCjfvPfpqQ3d9+PvWe+9dt/7z3zf2am8c3bl3v9ZwADPe6SGvSKYrGY8vLy+tyWe8cBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADATEZ/sirQX9zzF79Ja+5bE/zviL2p5B+9Z2Z/o8p7JrTjsPcM0N9xJQQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOEGphiQes/F0prrfOIe75nTuy94z3z3+1u8Z1b96QPeM+5o2HtGkor/6k3/IefS2hcGN66EAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAz3MAU+JTLv3rPe+ahv/zP3jNb1/yN98w70/xveqpp/iOSNH7UMu+ZsS+2ec/0nDzlPYOBhSshAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMBMwDnnrBfxafF4XOFwWOW6X0MDw6yXA2SF++Mve8/kPfs775mf/+t93jPpuvvAd7xn/s1fxrxneptPes/g1upxl9SgVxSLxZSXl9fntlwJAQDMECEAgBnvCB08eFALFixQUVGRAoGAdu3alfL60qVLFQgEUh7TpqX5Q00AAAOad4S6u7s1ceJE1dXVfeY28+fPV1tbW/Kxd+/ez7VIAMDA5P2TVSsrK1VZWdnnNsFgUJFIJO1FAQAGh6y8J9TQ0KCCggKNGzdOjz76qDo6Oj5z20QioXg8nvIAAAwOGY9QZWWltm7dqv379+u5555TU1OT5s6dq0QiccPta2trFQ6Hk4/i4uJMLwkA0E95/3XczSxevDj567KyMk2ePFklJSXas2ePFi1adN32q1atUnV1dfLreDxOiABgkMh4hK4VjUZVUlKi5ubmG74eDAYVDAazvQwAQD+U9e8T6uzsVGtrq6LRaLZ3BQDIMd5XQufPn9f777+f/LqlpUXvvPOO8vPzlZ+fr5qaGj344IOKRqM6deqUnnnmGY0ePVoPPPBARhcOAMh93hF6++23NWfOnOTXV9/PWbJkiTZu3Khjx45py5YtOnfunKLRqObMmaMdO3YoFAplbtUAgAGBG5gCOWJIYYH3zJnFX0prX2/9xQ+9Z25L42/3/6ylwnsmNrPTewa3FjcwBQDkBCIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJjJ+k9WBZAZvR90eM8U/q3/jCR98nSP98zIwHDvmRe/+D+8Z+57YIX3zMiX3/Kewa3BlRAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYbmAIGLs/8svfMP3/jdu+Zsi+f8p6R0rsZaTp+9OG/854Z+crbWVgJrHAlBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4QamwKcEJpd5z/zmz/1v9vniH2/2npl1+0XvmVsp4S55zxz+sNR/R5fb/GfQb3ElBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4Qam6PeGlpZ4z/zzt4rS2lfN4u3eMw/+wdm09tWfPfPBZO+Zxh9O8575o81ves9gYOFKCABghggBAMx4Rai2tlZTpkxRKBRSQUGBFi5cqBMnTqRs45xTTU2NioqKNGLECJWXl+v48eMZXTQAYGDwilBjY6Oqqqp0+PBh1dfXq6enRxUVFeru7k5us27dOq1fv151dXVqampSJBLRvHnz1NXVlfHFAwBym9cHE1599dWUrzdt2qSCggIdOXJEs2bNknNOGzZs0OrVq7Vo0SJJ0ubNm1VYWKht27bpsccey9zKAQA573O9JxSLxSRJ+fn5kqSWlha1t7eroqIiuU0wGNTs2bN16NChG/4eiURC8Xg85QEAGBzSjpBzTtXV1Zo5c6bKysokSe3t7ZKkwsLClG0LCwuTr12rtrZW4XA4+SguLk53SQCAHJN2hJYtW6Z3331XP//5z697LRAIpHztnLvuuatWrVqlWCyWfLS2tqa7JABAjknrm1WXL1+u3bt36+DBgxozZkzy+UgkIunKFVE0Gk0+39HRcd3V0VXBYFDBYDCdZQAAcpzXlZBzTsuWLdPOnTu1f/9+lZaWprxeWlqqSCSi+vr65HMXL15UY2OjZsyYkZkVAwAGDK8roaqqKm3btk2vvPKKQqFQ8n2ecDisESNGKBAIaMWKFVq7dq3Gjh2rsWPHau3atRo5cqQeeeSRrPwBAAC5yytCGzdulCSVl5enPL9p0yYtXbpUkvT000/rwoULevLJJ/XRRx9p6tSpeu211xQKhTKyYADAwBFwzjnrRXxaPB5XOBxWue7X0MAw6+WgD0O/eKf3TGxS9OYbXWPx9169+UbXePwPT3rP9Hcr2/xvEPrmC/43IpWk/Jf+p//Q5d609oWBp8ddUoNeUSwWU15eXp/bcu84AIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmEnrJ6ui/xoajXjPfPh3o9La1xOljd4zD4c+SGtf/dmyf5npPfNPG7/sPTP67/+X90x+15veM8CtxJUQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGG5jeIhf/w2T/mf/0offMM1/a6z1TMaLbe6a/+6D3Qlpzs3av9J65+7/8b++Z/HP+Nxa97D0B9H9cCQEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZriB6S1yaqF/738z4RdZWEnmPH/uLu+ZHzZWeM8EegPeM3d/v8V7RpLGfvCW90xvWnsCIHElBAAwRIQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYCTjnnPUiPi0ejyscDqtc92toYJj1cgAAnnrcJTXoFcViMeXl5fW5LVdCAAAzRAgAYMYrQrW1tZoyZYpCoZAKCgq0cOFCnThxImWbpUuXKhAIpDymTZuW0UUDAAYGrwg1NjaqqqpKhw8fVn19vXp6elRRUaHu7u6U7ebPn6+2trbkY+/evRldNABgYPD6yaqvvvpqytebNm1SQUGBjhw5olmzZiWfDwaDikQimVkhAGDA+lzvCcViMUlSfn5+yvMNDQ0qKCjQuHHj9Oijj6qjo+Mzf49EIqF4PJ7yAAAMDmlHyDmn6upqzZw5U2VlZcnnKysrtXXrVu3fv1/PPfecmpqaNHfuXCUSiRv+PrW1tQqHw8lHcXFxuksCAOSYtL9PqKqqSnv27NEbb7yhMWPGfOZ2bW1tKikp0fbt27Vo0aLrXk8kEimBisfjKi4u5vuEACBH+XyfkNd7QlctX75cu3fv1sGDB/sMkCRFo1GVlJSoubn5hq8Hg0EFg8F0lgEAyHFeEXLOafny5Xr55ZfV0NCg0tLSm850dnaqtbVV0Wg07UUCAAYmr/eEqqqq9LOf/Uzbtm1TKBRSe3u72tvbdeHCBUnS+fPn9dRTT+nNN9/UqVOn1NDQoAULFmj06NF64IEHsvIHAADkLq8roY0bN0qSysvLU57ftGmTli5dqiFDhujYsWPasmWLzp07p2g0qjlz5mjHjh0KhUIZWzQAYGDw/uu4vowYMUL79u37XAsCAAwe3DsOAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGBmqPUCruWckyT16JLkjBcDAPDWo0uS/v9/z/vS7yLU1dUlSXpDe41XAgD4PLq6uhQOh/vcJuB+n1TdQpcvX9aZM2cUCoUUCARSXovH4youLlZra6vy8vKMVmiP43AFx+EKjsMVHIcr+sNxcM6pq6tLRUVFuu22vt/16XdXQrfddpvGjBnT5zZ5eXmD+iS7iuNwBcfhCo7DFRyHK6yPw82ugK7igwkAADNECABgJqciFAwGtWbNGgWDQeulmOI4XMFxuILjcAXH4YpcOw797oMJAIDBI6euhAAAAwsRAgCYIUIAADNECABgJqci9MILL6i0tFS33367Jk2apNdff916SbdUTU2NAoFAyiMSiVgvK+sOHjyoBQsWqKioSIFAQLt27Up53TmnmpoaFRUVacSIESovL9fx48dtFptFNzsOS5cuve78mDZtms1is6S2tlZTpkxRKBRSQUGBFi5cqBMnTqRsMxjOh9/nOOTK+ZAzEdqxY4dWrFih1atX6+jRo7r33ntVWVmp06dPWy/tlho/frza2tqSj2PHjlkvKeu6u7s1ceJE1dXV3fD1devWaf369aqrq1NTU5MikYjmzZuXvA/hQHGz4yBJ8+fPTzk/9u4dWPdgbGxsVFVVlQ4fPqz6+nr19PSooqJC3d3dyW0Gw/nw+xwHKUfOB5cjvvrVr7rHH3885bm7777bffe73zVa0a23Zs0aN3HiROtlmJLkXn755eTXly9fdpFIxD377LPJ5z755BMXDofdj3/8Y4MV3hrXHgfnnFuyZIm7//77TdZjpaOjw0lyjY2NzrnBez5cexycy53zISeuhC5evKgjR46ooqIi5fmKigodOnTIaFU2mpubVVRUpNLSUj300EM6efKk9ZJMtbS0qL29PeXcCAaDmj179qA7NySpoaFBBQUFGjdunB599FF1dHRYLymrYrGYJCk/P1/S4D0frj0OV+XC+ZATETp79qx6e3tVWFiY8nxhYaHa29uNVnXrTZ06VVu2bNG+ffv04osvqr29XTNmzFBnZ6f10sxc/ec/2M8NSaqsrNTWrVu1f/9+Pffcc2pqatLcuXOVSCSsl5YVzjlVV1dr5syZKisrkzQ4z4cbHQcpd86HfncX7b5c+6MdnHPXPTeQVVZWJn89YcIETZ8+XXfddZc2b96s6upqw5XZG+znhiQtXrw4+euysjJNnjxZJSUl2rNnjxYtWmS4suxYtmyZ3n33Xb3xxhvXvTaYzofPOg65cj7kxJXQ6NGjNWTIkOv+T6ajo+O6/+MZTEaNGqUJEyaoubnZeilmrn46kHPjetFoVCUlJQPy/Fi+fLl2796tAwcOpPzol8F2PnzWcbiR/no+5ESEhg8frkmTJqm+vj7l+fr6es2YMcNoVfYSiYTee+89RaNR66WYKS0tVSQSSTk3Ll68qMbGxkF9bkhSZ2enWltbB9T54ZzTsmXLtHPnTu3fv1+lpaUprw+W8+Fmx+FG+u35YPihCC/bt293w4YNcz/96U/dr3/9a7dixQo3atQod+rUKeul3TIrV650DQ0N7uTJk+7w4cPuvvvuc6FQaMAfg66uLnf06FF39OhRJ8mtX7/eHT161P32t791zjn37LPPunA47Hbu3OmOHTvmHn74YReNRl08HjdeeWb1dRy6urrcypUr3aFDh1xLS4s7cOCAmz59uvvCF74woI7DE0884cLhsGtoaHBtbW3Jx8cff5zcZjCcDzc7Drl0PuRMhJxz7vnnn3clJSVu+PDh7itf+UrKxxEHg8WLF7toNOqGDRvmioqK3KJFi9zx48etl5V1Bw4ccJKueyxZssQ5d+VjuWvWrHGRSMQFg0E3a9Ysd+zYMdtFZ0Ffx+Hjjz92FRUV7o477nDDhg1zd955p1uyZIk7ffq09bIz6kZ/fklu06ZNyW0Gw/lws+OQS+cDP8oBAGAmJ94TAgAMTEQIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAmf8Lw4IYymq+HboAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = keras.saving.load_model('models/1730030314')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = keras.models.load_model('models/DIGITZ_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0395 - accuracy: 0.9922 - 618ms/epoch - 2ms/step\n",
      "\n",
      "Test accuracy: 0.9922000169754028\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       980\n",
      "           1       1.00      1.00      1.00      1135\n",
      "           2       0.99      0.99      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.99      0.99      0.99      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       0.99      0.98      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "[[ 978    0    0    0    0    0    1    1    0    0]\n",
      " [   0 1132    0    0    0    1    0    0    1    1]\n",
      " [   1    0 1026    1    0    0    1    3    0    0]\n",
      " [   0    0    3 1000    0    4    0    2    1    0]\n",
      " [   0    0    0    0  973    0    1    2    1    5]\n",
      " [   0    0    0    4    0  885    2    0    0    1]\n",
      " [   3    2    0    1    0    3  947    0    1    1]\n",
      " [   0    1    3    1    0    0    0 1022    0    1]\n",
      " [   2    0    3    0    0    1    0    0  966    2]\n",
      " [   0    1    0    0    5    3    0    5    2  993]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model_load.evaluate(x_test_normalized, y_test_cat, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc}')\n",
    "\n",
    "# Print classification report\n",
    "y_pred = model_load.predict(x_test_normalized)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test_cat, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
